{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "distribution git.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oHP6quamKpem",
        "7_Aro-tEK5zL",
        "3_HR2r0oK-Am",
        "F-q9ec13VV5z",
        "jMjTiLjZ_nUO",
        "0SV9TcHxDotZ",
        "-b245eNov4b1",
        "B-_X32rvD9up",
        "ZwCV-Heyvw9u",
        "1VOWD2aPGT43"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2ed6928058a439cbe04c48c426c24ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_52a2bc3477d94c469b3e34e66f7e12b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0d7f80cfaa7e4145b46bb7f7082aa5e8",
              "IPY_MODEL_f0bc575f6e87490b93d212c72b2b6548"
            ]
          }
        },
        "52a2bc3477d94c469b3e34e66f7e12b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d7f80cfaa7e4145b46bb7f7082aa5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da86c576cb0c47999fe61b5ffb4b9b7b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_015a989c7bd64522ba5fc166f0f9e01a"
          }
        },
        "f0bc575f6e87490b93d212c72b2b6548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0785dc5693b649faba427adaeb32dfd2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:10&lt;00:00, 913899.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55399320b9054fbc936f35ad550f4343"
          }
        },
        "da86c576cb0c47999fe61b5ffb4b9b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "015a989c7bd64522ba5fc166f0f9e01a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0785dc5693b649faba427adaeb32dfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55399320b9054fbc936f35ad550f4343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60aeefc3ccd748d39648b6be59583b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7bb5a00682754668908657ec3c6c285e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_72365f84a9fc42bdb56ba6208a74e397",
              "IPY_MODEL_ea29382ae38c48c9b86f61b06a9b35db"
            ]
          }
        },
        "7bb5a00682754668908657ec3c6c285e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "72365f84a9fc42bdb56ba6208a74e397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da2b6c31f6274c89abd1f2955b39c4c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb9f12c2ba5845dea5c4f81e64981d97"
          }
        },
        "ea29382ae38c48c9b86f61b06a9b35db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6fff2c85b5340dd9948dd9a73d2ff3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:02&lt;00:00, 13738.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfbb58fddcaf42a796b4e154320d8887"
          }
        },
        "da2b6c31f6274c89abd1f2955b39c4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb9f12c2ba5845dea5c4f81e64981d97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6fff2c85b5340dd9948dd9a73d2ff3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfbb58fddcaf42a796b4e154320d8887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0186be7104034d0aa714fab81111f19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1d08ae3437f441490d4c12554976de2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ffdeefbb7d804c7eafadc41f18d45925",
              "IPY_MODEL_046c4f3b5c17420aba021fcc6696956b"
            ]
          }
        },
        "e1d08ae3437f441490d4c12554976de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffdeefbb7d804c7eafadc41f18d45925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6dc7a3842e834dd388c6e820e29a480b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b65112d9ea8847fb9e414212aaa9d652"
          }
        },
        "046c4f3b5c17420aba021fcc6696956b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ffb486eb49e84beca6cf5e2a84957671",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:04&lt;00:00, 396667.42it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_083cb8f95b7540129f95fbd895c41d31"
          }
        },
        "6dc7a3842e834dd388c6e820e29a480b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b65112d9ea8847fb9e414212aaa9d652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffb486eb49e84beca6cf5e2a84957671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "083cb8f95b7540129f95fbd895c41d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13233f6f6e6041a4afe6e809620ee0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9700f073c9a741f59fd5febdf962d2d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_97efdc84f6b74b549f6d4a899e406dc7",
              "IPY_MODEL_3b3803f953b64de18b6334fe254d6fab"
            ]
          }
        },
        "9700f073c9a741f59fd5febdf962d2d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "97efdc84f6b74b549f6d4a899e406dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53b766107f624258b3f999c74ca4e060",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_093d9e05b98247a69f04d6144bcccb1b"
          }
        },
        "3b3803f953b64de18b6334fe254d6fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a30ca943865e46f797b9227116e0b118",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:01&lt;00:00, 2695.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af89198f3e144d3eae4d020178b8ddef"
          }
        },
        "53b766107f624258b3f999c74ca4e060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "093d9e05b98247a69f04d6144bcccb1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a30ca943865e46f797b9227116e0b118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af89198f3e144d3eae4d020178b8ddef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHP6quamKpem"
      },
      "source": [
        "# INITIALISATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-RRW9zgdKv5"
      },
      "source": [
        "from time import time\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from pathlib import Path\n",
        "from IPython.display import Image, display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms.functional import to_pil_image, resize, to_tensor\n",
        "from torchvision.transforms.functional import normalize\n",
        "# from tqdm.notebook import tqdm\n",
        "import os\n",
        "import random\n",
        "from copy import deepcopy\n",
        "from zipfile import ZipFile, ZIP_DEFLATED"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcpDqZ1gts-9"
      },
      "source": [
        "SEEDS = [0,1,2,3,4]\n",
        "EPOCHS = 100\n",
        "FORCE = False\n",
        "INTENS = 0.4\n",
        "METRICS = (\"fit\", \"gen\", \"reg\", \"acc\", \"l2_dist\", \"l2_norm\", \"grad_sp\", \"grad_norm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtHuJPre3AdE"
      },
      "source": [
        "os.chdir(\"/content\")\n",
        "os.makedirs(\"plots\", exist_ok=True)\n",
        "os.chdir(\"/content/plots\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Aro-tEK5zL"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3plCM_hmKD2D"
      },
      "source": [
        "## functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cChzUjVOMNc3"
      },
      "source": [
        "# data import and management\n",
        "\n",
        "def load_mnist(img_size=32):\n",
        "    ''' return data and labels for train and test mnist dataset '''\n",
        "    #---------------- train data -------------------\n",
        "    mnist_train = datasets.MNIST('data', train=True, download=True)\n",
        "    data_train = mnist_train.data\n",
        "    labels_train = [mnist_train[i][1] for i in range(len(data_train))]\n",
        "\n",
        "    pics = []\n",
        "    for pic in data_train:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size) # Resize image if needed\n",
        "        pic = to_tensor(pic)            # Tensor conversion normalizes in [0,1]\n",
        "        pics.append(pic)\n",
        "    data_train = torch.stack(pics)\n",
        "\n",
        "    #------------------  test data -----------------------\n",
        "    mnist_test = datasets.MNIST('data', train=False, download=True)\n",
        "    data_test = mnist_test.data\n",
        "    labels_test = [mnist_test[i][1] for i in range(len(data_test))]\n",
        "\n",
        "    pics = []\n",
        "    for pic in data_test:\n",
        "        pic = to_pil_image(pic)\n",
        "        if img_size != 28:\n",
        "            pic = resize(pic, img_size)   # Resize image if needed\n",
        "        pic = to_tensor(pic)             # Tensor conversion normalizes in [0,1]\n",
        "        pics.append(pic)\n",
        "    data_test = torch.stack(pics)\n",
        "\n",
        "    return (data_train,labels_train), (data_test,labels_test)\n",
        "\n",
        "def query(datafull, nb, bias=0, fav=0):\n",
        "    ''' return -nb random samples of -datafull '''\n",
        "    data, labels = datafull\n",
        "    idxs = list(range(len(data)))\n",
        "    l = []\n",
        "    h, w = data[0][0].shape\n",
        "    d = torch.empty(nb, 1, h, w)\n",
        "    if bias == 0:\n",
        "        indexes = random.sample(idxs, nb) # drawing nb random indexes\n",
        "    else :\n",
        "        indexes = []\n",
        "        for i in range(nb):\n",
        "            idx = one_query(labels, idxs, bias, fav)\n",
        "            indexes.append(idx)\n",
        "            idxs.remove(idx) # to draw only once each index max\n",
        "    for k, i in enumerate(indexes): # filling our query\n",
        "        d[k] = data[i]\n",
        "        l.append(labels[i])\n",
        "    return d, l\n",
        "\n",
        "def one_query(labels, idxs, redraws, fav):\n",
        "    ''' labels : list of labels\n",
        "        idxs : list of available indexes\n",
        "        draws an index with a favorite label choice \n",
        "        fav : favorite label\n",
        "        redraws : max nb of random redraws while fav not found\n",
        "    '''\n",
        "    lab = -1 \n",
        "    while lab != fav and redraws >= 0:\n",
        "        idx = idxs[random.randint(0, len(idxs)-1)]\n",
        "        lab = labels[idx]\n",
        "        redraws -= 1\n",
        "    return idx\n",
        "\n",
        "def list_to_longtens(l):\n",
        "    ''' change a list into torch.long tensor '''\n",
        "    tens = torch.empty(len(l), dtype=torch.long)  \n",
        "    for i, lab in enumerate(l):                       \n",
        "        tens[i] = lab\n",
        "    return tens\n",
        "\n",
        "def swap(l, n, m):\n",
        "    ''' swap n and m values in l list '''\n",
        "    return [m if (v==n) else n if (v==m) else v for v in l]\n",
        "\n",
        "\n",
        "def distribute_data_rd(datafull, distrib, fav_lab=(0,0), \n",
        "                       dish=False, dish_lab=0, gpu=True): \n",
        "    '''draw random data on N nodes following distrib\n",
        "        data, labels : raw data and labels\n",
        "        distrib : int list, list of nb of data points for each node\n",
        "        pref_lab : (prefered label, strength of preference (int))\n",
        "        dish : boolean, if nodes are dishonest \n",
        "        dish_lab : 0 to 4, labelisation method\n",
        "\n",
        "        returns : (list of batches of images, list of batches of labels)\n",
        "    '''\n",
        "    global FORCING1\n",
        "    global FORCING2\n",
        "    global FORCE\n",
        "    data, labels = datafull\n",
        "    N = len(distrib)\n",
        "    data_dist = []      # list of len N\n",
        "    labels_dist = []    # list of len N\n",
        "    fav, strength = fav_lab\n",
        "\n",
        "    for n, number in enumerate(distrib): #for each node\n",
        "        # if strength == 0:  # if no preference\n",
        "        d, l = query(datafull, number, strength, fav)\n",
        "        # else:\n",
        "        #     d, l = query(datafull, number, strength, fav)\n",
        "        if gpu:\n",
        "            data_dist.append(torch.FloatTensor(d).cuda())\n",
        "        else:\n",
        "            data_dist.append(torch.FloatTensor(d))\n",
        "        if dish:                # if dishonest node\n",
        "\n",
        "            # labels modification\n",
        "            if dish_lab == 0: # random\n",
        "                tens = torch.randint(10, (number,), dtype=torch.long)\n",
        "            elif dish_lab == 1: # zeros\n",
        "                tens = torch.zeros(number, dtype=torch.long)\n",
        "            elif dish_lab == 2: # swap 1-7\n",
        "                l = swap(l, 1, 7)\n",
        "                tens = list_to_longtens(l)\n",
        "            elif dish_lab == 3: # swap 2 random (maybe same)\n",
        "                if FORCE: # to force same swap multiple times\n",
        "                    if FORCING1 == -1:\n",
        "                        FORCING1, FORCING2 = random.randint(0,9), random.randint(0,9)\n",
        "                    l = swap(l, FORCING1, FORCING2)    \n",
        "                else:         \n",
        "                    n, m = random.randint(0,9), random.randint(0,9)\n",
        "                    l = swap(l, n, m)\n",
        "                tens = list_to_longtens(l)\n",
        "              \n",
        "            elif dish_lab == 4: # label +1\n",
        "                tens = (list_to_longtens(l) + 1) % 10\n",
        "\n",
        "        else:           # if honest node \n",
        "            tens = list_to_longtens(l) # needed for CrossEntropy later\n",
        "        if gpu:\n",
        "            tens = tens.cuda()\n",
        "        labels_dist.append(tens)\n",
        "\n",
        "    return data_dist, labels_dist\n",
        "\n",
        "def zipping(dir_name):\n",
        "    '''zip a local folder to local directory'''\n",
        "    f = ZipFile(dir_name +'.zip', mode='w', compression=ZIP_DEFLATED)\n",
        "    for fil in os.listdir(dir_name):\n",
        "        if fil[0] != \".\":\n",
        "            f.write(dir_name +'/' + fil)\n",
        "    f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHCoX9RGMtoI"
      },
      "source": [
        "## get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4inHbdwNgz4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811,
          "referenced_widgets": [
            "d2ed6928058a439cbe04c48c426c24ac",
            "52a2bc3477d94c469b3e34e66f7e12b2",
            "0d7f80cfaa7e4145b46bb7f7082aa5e8",
            "f0bc575f6e87490b93d212c72b2b6548",
            "da86c576cb0c47999fe61b5ffb4b9b7b",
            "015a989c7bd64522ba5fc166f0f9e01a",
            "0785dc5693b649faba427adaeb32dfd2",
            "55399320b9054fbc936f35ad550f4343",
            "60aeefc3ccd748d39648b6be59583b12",
            "7bb5a00682754668908657ec3c6c285e",
            "72365f84a9fc42bdb56ba6208a74e397",
            "ea29382ae38c48c9b86f61b06a9b35db",
            "da2b6c31f6274c89abd1f2955b39c4c6",
            "fb9f12c2ba5845dea5c4f81e64981d97",
            "d6fff2c85b5340dd9948dd9a73d2ff3f",
            "bfbb58fddcaf42a796b4e154320d8887",
            "0186be7104034d0aa714fab81111f19f",
            "e1d08ae3437f441490d4c12554976de2",
            "ffdeefbb7d804c7eafadc41f18d45925",
            "046c4f3b5c17420aba021fcc6696956b",
            "6dc7a3842e834dd388c6e820e29a480b",
            "b65112d9ea8847fb9e414212aaa9d652",
            "ffb486eb49e84beca6cf5e2a84957671",
            "083cb8f95b7540129f95fbd895c41d31",
            "13233f6f6e6041a4afe6e809620ee0f9",
            "9700f073c9a741f59fd5febdf962d2d1",
            "97efdc84f6b74b549f6d4a899e406dc7",
            "3b3803f953b64de18b6334fe254d6fab",
            "53b766107f624258b3f999c74ca4e060",
            "093d9e05b98247a69f04d6144bcccb1b",
            "a30ca943865e46f797b9227116e0b118",
            "af89198f3e144d3eae4d020178b8ddef"
          ]
        },
        "outputId": "83daa7c1-8042-410c-af91-2aead3112dcb"
      },
      "source": [
        "# downloading data\n",
        "if 'train' not in globals(): # to avoid loading data every time\n",
        "    train, test = load_mnist()\n",
        "    test_gpu = torch.tensor(test[0]).cuda(), torch.tensor(test[1]).cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2ed6928058a439cbe04c48c426c24ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60aeefc3ccd748d39648b6be59583b12",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0186be7104034d0aa714fab81111f19f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13233f6f6e6041a4afe6e809620ee0f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Processing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_HR2r0oK-Am"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QclvVEyDa4G"
      },
      "source": [
        "#model structure\n",
        "\n",
        "def get_classifier():\n",
        "    ''' returns linear baseline classifier '''\n",
        "    model = nn.Sequential( \n",
        "        nn.Flatten(),\n",
        "        nn.Linear(1024, 10),\n",
        "        # nn.Sigmoid()\n",
        "        )\n",
        "    return model\n",
        "\n",
        "\n",
        "# def get_classifier():\n",
        "#     ''' returns classifier '''\n",
        "#     chan = 16\n",
        "#     model = nn.Sequential( \n",
        "#         nn.Conv2d(1, chan, kernel_size=3, padding=0),\n",
        "#         nn.Flatten(),\n",
        "#         nn.Linear(900 * chan, 10),\n",
        "#         nn.Sigmoid()\n",
        "#         )\n",
        "#     return model\n",
        "\n",
        "# class classifier(nn.Module):\n",
        "#     '''CNN Model'''\n",
        "#     def __init__(self):\n",
        "#         super(classifier, self).__init__()\n",
        "        \n",
        "#         # Convolution 1\n",
        "#         self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16,\n",
        "#                               kernel_size=3, stride=1, padding=0)\n",
        "#         self.relu1 = nn.ReLU()\n",
        "#         # Max pool 1\n",
        "#         self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "#         # Convolution 2\n",
        "#         self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, \n",
        "#                               kernel_size=3, stride=1, padding=0)\n",
        "#         self.relu2 = nn.ReLU()      \n",
        "#         # Max pool 2\n",
        "#         self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "#         # Fully connected 1\n",
        "#         self.fc1 = nn.Linear(32 * 6 * 6, 10) \n",
        "    \n",
        "#     def forward(self, x):\n",
        "#         # Set 1\n",
        "#         out = self.cnn1(x)\n",
        "#         out = self.relu1(out)\n",
        "#         out = self.maxpool1(out)  \n",
        "#         # Set 2\n",
        "#         out = self.cnn2(out)\n",
        "#         out = self.relu2(out)\n",
        "#         out = self.maxpool2(out)\n",
        "#         #Flatten\n",
        "#         out = out.view(out.size(0), -1)\n",
        "#         #Dense\n",
        "#         out = self.fc1(out)\n",
        "#         return out\n",
        "# def get_classifier():\n",
        "#     return classifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ0v-iNHLBr4"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-q9ec13VV5z"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PH-0T9rrdr8"
      },
      "source": [
        "#loss and scoring functions \n",
        "\n",
        "def local_loss(model_loc, x, y):  \n",
        "    ''' classification loss '''\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    predicted = model_loc(x)\n",
        "    local = loss(predicted,y)\n",
        "    return local\n",
        "\n",
        "def models_dist(model_loc, model_glob, pow=(1,1)):  \n",
        "    ''' l1 distance between global and local parameter\n",
        "        will be mutliplied by w_n \n",
        "        pow : (internal power, external power)\n",
        "    '''\n",
        "    q, p = pow\n",
        "    dist = sum(((theta - rho)**q).abs().sum() for theta, rho in \n",
        "                  zip(model_loc.parameters(), model_glob.parameters()))**p\n",
        "    return dist\n",
        "\n",
        "def model_norm(model_glob, pow=(2,1)): \n",
        "    ''' l2 squared regularisation of global parameter\n",
        "     will be multiplied by w_0 \n",
        "     pow : (internal power, external power)\n",
        "     '''\n",
        "    q, p = pow\n",
        "    norm = sum((param**q).abs().sum() for param in model_glob.parameters())**p\n",
        "    return norm\n",
        "\n",
        "def round_loss(tens, dec=0): \n",
        "    '''from an input scalar tensor returns rounded integer'''\n",
        "    if type(tens)==int or type(tens)==float:\n",
        "        return round(tens, dec)\n",
        "    else:\n",
        "        return round(tens.item(), dec)\n",
        "\n",
        "def tens_count(tens, val):\n",
        "    ''' counts nb of -val in tensor -tens '''\n",
        "    return len(tens) - round_loss(torch.count_nonzero(tens-val))\n",
        "\n",
        "def score(model, datafull):\n",
        "    ''' returns accuracy provided models, images and GTs '''\n",
        "    out = model(datafull[0])\n",
        "    predictions = torch.max(out, 1)[1]\n",
        "    c=0\n",
        "    for a, b in zip(predictions, datafull[1]):\n",
        "        c += int(a==b)\n",
        "    return c/len(datafull[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC1BWA7Kk99I"
      },
      "source": [
        "## Flower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMjTiLjZ_nUO"
      },
      "source": [
        "### flower class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CccpUZLozYXm"
      },
      "source": [
        "# nodes repartition\n",
        "\n",
        "class Flower():\n",
        "    ''' Training structure including local models and general one \n",
        "        Allowing to add and remove nodes at will\n",
        "        .pop\n",
        "        .add_nodes\n",
        "        .rem_nodes\n",
        "        .train\n",
        "        .display\n",
        "        .check\n",
        "    '''\n",
        "\n",
        "    def __init__(self, test, w0, opt=optim.Adam, gpu=True):\n",
        "        ''' opt : optimizer\n",
        "            test : test data couple (imgs,labels)\n",
        "            w0 : regularisation strength\n",
        "        '''\n",
        "        self.d_test = test\n",
        "        self.w = w0\n",
        "        self.gpu = gpu\n",
        "\n",
        "        self.opt = opt\n",
        "        self.lr_node = 0.001\n",
        "        self.lr_gen = 0.001\n",
        "        self.gen_freq = 1  # generalisation frequency (>0) \n",
        "        if self.gpu:\n",
        "            self.general_model = get_classifier().cuda() \n",
        "        else:\n",
        "            self.general_model = get_classifier()\n",
        "        self.init_model = deepcopy(self.general_model)\n",
        "        self.last_grad = None\n",
        "        self.opt_gen = self.opt(self.general_model.parameters(), lr=self.lr_gen)\n",
        "        self.pow_gen = (1,1)  # choice of norms for Licchavi loss \n",
        "        self.pow_reg = (2,1)  # (internal power, external power)\n",
        "        self.data = []\n",
        "        self.labels = [] \n",
        "        self.typ = []\n",
        "        self.models = []\n",
        "        self.W = []\n",
        "        self.age = []\n",
        "        self.opt_nodes = []\n",
        "        self.nb_nodes = 0\n",
        "        self.dic = {\"honest\" : -1, \"trolls\" : 0, \"zeros\" : 1, \n",
        "                    \"one_evil\" : 2, \"strats\" : 3, \"jokers\" : 4, \"byzantine\" : -1}\n",
        "        self.history = ([], [], [], [], [], [], [], []) \n",
        "        # self.h_legend = (\"fit\", \"gen\", \"reg\", \"acc\", \"l2_dist\", \"l2_norm\", \"grad_sp\", \"grad_norm\")\n",
        "        self.localtest = ([], []) # (which to pick for each node, list of (data,labels) pairs)\n",
        "\n",
        "    # ------------ population methods --------------------\n",
        "    def set_localtest(self, datafull, size, nodes, fav_lab=(0,0), typ=\"honest\"):\n",
        "        ''' create a local data for some nodes\n",
        "            datafull : source data\n",
        "            size : size of test sample\n",
        "            fav_labs : (label, strength)\n",
        "            nodes : list of nodes which use this data           \n",
        "        '''\n",
        "        id = self.dic[typ]\n",
        "        dish = (id != -1) # boolean for dishonesty\n",
        "        dt, lb = distribute_data_rd(datafull, [size], fav_lab,\n",
        "                                    dish, dish_lab=id, gpu=self.gpu)\n",
        "        dtloc = (dt[0], lb[0])\n",
        "        self.localtest[1].append(dtloc)\n",
        "        id = len(self.localtest[1]) - 1\n",
        "        for n in nodes:\n",
        "            self.localtest[0][n] = id\n",
        "\n",
        "    def add_nodes(self, datafull, pop, typ, fav_lab=(0,0), w=0.01, verb=1):\n",
        "        ''' add nodes to the Flower \n",
        "            datafull : data to put on node (sampled from it)\n",
        "            pop : (nb of nodes, size of nodes)\n",
        "            typ : type of nodes (str keywords)\n",
        "            fav_lab : (favorite label, strength)\n",
        "            w : int, weight of new nodes\n",
        "        '''\n",
        "        nb, size = pop\n",
        "        id = self.dic[typ]\n",
        "        dish = (id != -1) # boolean for dishonesty\n",
        "        dt, lb = distribute_data_rd(datafull, [size] * nb, fav_lab,\n",
        "                                    dish, dish_lab=id, gpu=self.gpu)\n",
        "        self.data += dt\n",
        "        self.labels += lb\n",
        "        self.typ += [typ] * nb\n",
        "        if self.gpu:\n",
        "            self.models += [get_classifier().cuda() for i in range(nb)]\n",
        "        else:\n",
        "            self.models += [get_classifier() for i in range(nb)]\n",
        "        self.W += [w] * nb\n",
        "        self.age += [0] * nb\n",
        "        for i in range(nb):\n",
        "            self.localtest[0].append(-1)\n",
        "        self.nb_nodes += nb\n",
        "        self.opt_nodes += [self.opt(self.models[n].parameters(), lr=self.lr_node) \n",
        "            for n in range(self.nb_nodes - nb, self.nb_nodes) \n",
        "            ]\n",
        "        if verb:\n",
        "            print(\"Added {} {} nodes of {} data points\".format(nb, typ, size))\n",
        "            print(\"Total number of nodes : {}\".format(self.nb_nodes))\n",
        "\n",
        "    def rem_nodes(self, first, last, verb=1):\n",
        "        ''' remove nodes of indexes -first (included) to -last (excluded) '''\n",
        "        nb = last - first\n",
        "        if last > self.nb_nodes:\n",
        "            print(\"-last is out of range, remove canceled\")\n",
        "        else:\n",
        "            del self.data[first : last]\n",
        "            del self.labels[first : last] \n",
        "            del self.typ[first : last]\n",
        "            del self.models[first : last]\n",
        "            del self.W[first : last]\n",
        "            del self.age[first : last]\n",
        "            del self.opt_nodes[first : last]\n",
        "            del self.localtest[0][first : last]\n",
        "            self.nb_nodes -= nb\n",
        "            if verb: print(\"Removed {} nodes\".format(nb))\n",
        "        \n",
        "    def hm(self, ty):\n",
        "        ''' count nb of nodes of this type '''\n",
        "        return self.typ.count(ty)\n",
        "    \n",
        "    def pop(self):\n",
        "        ''' return dictionnary of population '''\n",
        "        c = {}\n",
        "        for ty in self.dic.keys():\n",
        "            c[ty] = self.hm(ty)\n",
        "        return c\n",
        "\n",
        "    # ------------- scoring methods -----------\n",
        "    def score_glob(self, datafull): \n",
        "        ''' return accuracy provided images and GTs '''\n",
        "        return score(self.general_model, datafull)\n",
        "    \n",
        "    def test_loc(self, node):\n",
        "        ''' score of node on local test data '''\n",
        "        id_data = self.localtest[0][node]\n",
        "        if id_data == -1:\n",
        "            # print(\"No local test data\")\n",
        "            return None\n",
        "        else:\n",
        "            nodetest = score(self.models[node], self.localtest[1][id_data])\n",
        "            return nodetest\n",
        "\n",
        "    def test_full(self, node):\n",
        "        ''' score of node on global test data '''\n",
        "        return score(self.models[node], self.d_test)\n",
        "\n",
        "    def test_train(self, node):\n",
        "        ''' score of node on its train data '''\n",
        "        return score(self.models[node], (self.data[node], self.labels[node]))\n",
        "\n",
        "    def display(self, node):\n",
        "        ''' display accuracy for selected node\n",
        "            node = -1 for global model\n",
        "        '''\n",
        "        if node == -1: # global model\n",
        "            print(\"global model\")\n",
        "            print(\"accuracy on test data :\", \n",
        "                  self.score_glob(self.d_test))\n",
        "        else: # we asked for a node\n",
        "            loc_train = self.test_train(node)\n",
        "            loc_test = self.test_loc(node)\n",
        "            full_test = self.test_full(node)\n",
        "            print(\"node number :\", node, \", dataset size :\",\n",
        "                len(self.labels[node]), \", type :\", self.typ[node], \n",
        "                \", age :\", self.age[node])\n",
        "            print(\"accuracy on local train data :\", loc_train)\n",
        "            print(\"accuracy on local test data :\", loc_test)\n",
        "            print(\"accuracy on global test data :\", full_test)\n",
        "            repart = {str(k) : tens_count(self.labels[node], k) \n",
        "                for k in range(10)}\n",
        "            print(\"labels repartition :\", repart)\n",
        "    \n",
        "    # ---------- methods for training ------------\n",
        "\n",
        "    def _set_lr(self):\n",
        "        '''set learning rates of optimizers according to Flower setting'''\n",
        "        for n in range(self.nb_nodes):  # updating lr in optimizers\n",
        "            self.opt_nodes[n].param_groups[0]['lr'] = self.lr_node\n",
        "        self.opt_gen.param_groups[0]['lr'] = self.lr_gen\n",
        "\n",
        "    def _zero_opt(self):\n",
        "        '''reset gradients of all models'''\n",
        "        for n in range(self.nb_nodes):\n",
        "            self.opt_nodes[n].zero_grad()      \n",
        "        self.opt_gen.zero_grad()\n",
        "\n",
        "    def _update_hist(self, epoch, test_freq, fit, gen, reg, verb=1):\n",
        "        '''update history'''\n",
        "        if epoch  % test_freq == 0:   # printing accuracy on test data\n",
        "            acc = self.score_glob(self.d_test)\n",
        "            if verb: print(\"TEST ACCURACY : \", acc)\n",
        "            for i in range(test_freq):\n",
        "                self.history[3].append(acc) \n",
        "        self.history[0].append(round_loss(fit))\n",
        "        self.history[1].append(round_loss(gen))\n",
        "        self.history[2].append(round_loss(reg))\n",
        "\n",
        "        dist = models_dist(self.init_model, self.general_model, pow=(2,0.5)) \n",
        "        norm = model_norm(self.general_model, pow=(2,0.5))\n",
        "        self.history[4].append(round_loss(dist, 1))\n",
        "        self.history[5].append(round_loss(norm, 1))\n",
        "        grad_gen = extract_grad(self.general_model)\n",
        "        if epoch > 1: # no last model for first epoch\n",
        "            scal_grad = sp(self.last_grad, grad_gen)\n",
        "            self.history[6].append(scal_grad)\n",
        "        else:\n",
        "            self.history[6].append(0) # default value for first epoch\n",
        "        self.last_grad = deepcopy(extract_grad(self.general_model)) \n",
        "        grad_norm = sp(grad_gen, grad_gen)  # use sqrt ?\n",
        "        self.history[7].append(grad_norm)\n",
        "\n",
        "    def _old(self, years):\n",
        "        ''' increment age (after training) '''\n",
        "        for i in range(self.nb_nodes):\n",
        "            self.age[i] += years\n",
        "\n",
        "    def _counters(self, c_gen, c_fit):\n",
        "        '''update internal training counters'''\n",
        "        fit_step = (c_fit >= c_gen) \n",
        "        if fit_step:\n",
        "            c_gen += self.gen_freq\n",
        "        else:\n",
        "            c_fit += 1 \n",
        "        return fit_step, c_gen, c_fit\n",
        "\n",
        "    def _do_step(self, fit_step):\n",
        "        '''step for appropriate optimizer(s)'''\n",
        "        if fit_step:       # updating local or global alternatively\n",
        "            for n in range(self.nb_nodes): \n",
        "                self.opt_nodes[n].step()      \n",
        "        else:\n",
        "            self.opt_gen.step()  \n",
        "\n",
        "    # ====================  TRAINING ================== \n",
        "\n",
        "    def train(self, nb_epochs=10, test_freq=1, verb=2):   \n",
        "        '''training loop'''\n",
        "        time_train = time()\n",
        "        self._set_lr()\n",
        "\n",
        "        # initialisation to avoid undefined variables at epoch 1\n",
        "        loss, fit_loss, gen_loss, reg_loss = 0, 0, 0, 0\n",
        "        c_fit, c_gen = 0, 0\n",
        "        reg_loss = self.w * model_norm(self.general_model, self.pow_reg)  \n",
        "\n",
        "        nb_steps = self.gen_freq + 1\n",
        "        for epoch in range(1, nb_epochs + 1):\n",
        "            if verb: print(\"\\nepoch {}/{}\".format(epoch, nb_epochs))\n",
        "            time_ep = time()\n",
        "\n",
        "            for step in range(1, nb_steps + 1):\n",
        "                fit_step, c_gen, c_fit = self._counters(c_gen, c_fit)\n",
        "                if verb >= 2: \n",
        "                    txt = \"(fit)\" if fit_step else \"(gen)\" \n",
        "                    print(\"step :\", step, '/', nb_steps, txt)\n",
        "                self._zero_opt() # resetting gradients\n",
        "\n",
        "\n",
        "                #----------------    Licchavi loss  -------------------------\n",
        "                 # only first 2 terms of loss updated\n",
        "                if fit_step:\n",
        "                    fit_loss, gen_loss, diff = 0, 0, 0\n",
        "                    for n in range(self.nb_nodes):   # for each node\n",
        "                        if self.typ[n] == \"byzantine\":\n",
        "                            fit = local_loss(self.models[n], \n",
        "                                             self.data[n], self.labels[n])\n",
        "                            fit_loss -= fit\n",
        "                            diff += 2 * fit\n",
        "                        else:\n",
        "                            fit_loss += local_loss(self.models[n], \n",
        "                                                self.data[n], self.labels[n])\n",
        "                        g = models_dist(self.models[n], \n",
        "                                        self.general_model, self.pow_gen)\n",
        "                        gen_loss +=  self.W[n] * g  # generalisation term   \n",
        "                    loss = fit_loss + gen_loss \n",
        "                          \n",
        "                # only last 2 terms of loss updated \n",
        "                else:        \n",
        "                    gen_loss, reg_loss = 0, 0\n",
        "                    for n in range(self.nb_nodes):   # for each node\n",
        "                        g = models_dist(self.models[n], \n",
        "                                        self.general_model, self.pow_gen)\n",
        "                        gen_loss += self.W[n] * g  #generalisation term    \n",
        "                    r = model_norm(self.general_model, self.pow_reg) \n",
        "                    reg_loss = self.w * r   # regul term  \n",
        "                    loss = gen_loss + reg_loss\n",
        "\n",
        "                total_out = round_loss(fit_loss + diff\n",
        "                    + gen_loss + reg_loss)\n",
        "                if verb >= 2:\n",
        "                    print(\"total loss : \", total_out)  # printing losses\n",
        "                    print(\"fitting : \", round_loss(fit_loss + diff),\n",
        "                        ', harmonisation : ', round_loss(gen_loss),\n",
        "                        ', regularisation : ', round_loss(reg_loss))\n",
        "\n",
        "                # Gradient descent \n",
        "                loss.backward() \n",
        "                self._do_step(fit_step)   \n",
        " \n",
        "            if verb: print(\"epoch time :\", round(time() - time_ep, 2)) \n",
        "            self._update_hist(epoch, test_freq, fit_loss, gen_loss, reg_loss, verb)\n",
        "            self._old(1)  # aging all nodes\n",
        "             \n",
        "        # ----------------- end of training -------------------------------  \n",
        "        for i in range(nb_epochs % test_freq): # to maintain same history length\n",
        "            self.history[3].append(acc)\n",
        "        print(\"training time :\", round(time() - time_train, 2)) \n",
        "        return self.history\n",
        "\n",
        "\n",
        "    # ------------ to check for problems --------------------------\n",
        "    def check(self):\n",
        "        ''' perform some tests on internal parameters adequation '''\n",
        "        # population check\n",
        "        b1 =  (self.nb_nodes == len(self.data) == len(self.labels) \n",
        "            == len(self.typ) == len(self.models) == len(self.opt_nodes) \n",
        "            == len(self.W) == len(self.age) == len(self.localtest[0]))\n",
        "        # history check\n",
        "        b2 = True\n",
        "        for l in self.history:\n",
        "            b2 = b2 and (len(l) == len(self.history[0]) >= max(self.age))\n",
        "        # local test data check\n",
        "        b3 = (max(self.localtest[0]) <= len(self.localtest[1]) - 1)\n",
        "        if (b1 and b2 and b3):\n",
        "            print(\"No Problem\")\n",
        "        else:\n",
        "            print(\"OULALA non ça va pas là\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMatkr4R_iWQ"
      },
      "source": [
        "### flower utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqix5WLBWpCp"
      },
      "source": [
        "def get_flower(w=0.05, gpu=True):\n",
        "    '''get a Flower using the appropriate test data (gpu or not)'''\n",
        "    if gpu:\n",
        "        return Flower(test_gpu, w, gpu=gpu)\n",
        "    else:\n",
        "        return Flower(test, w, gpu=gpu)\n",
        "\n",
        "# def grad_sp(m1, m2):\n",
        "#     ''' scalar product of gradients of 2 models '''\n",
        "#     s = 0\n",
        "#     for p1, p2 in zip(m1.parameters(), m2.parameters()):\n",
        "#         s += (p1.grad * p2.grad).sum()\n",
        "#     return s\n",
        "\n",
        "def extract_grad(model):\n",
        "    '''return list of gradients of a model'''\n",
        "    l_grad =  [p.grad for p in model.parameters()]\n",
        "    return l_grad\n",
        "\n",
        "def sp(l_grad1, l_grad2):\n",
        "    '''scalar product of 2 lists of gradients'''\n",
        "    s = 0\n",
        "    for g1, g2 in zip(l_grad1, l_grad2):\n",
        "        s += (g1 * g2).sum()\n",
        "    return round_loss(s, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNiOich9viuc"
      },
      "source": [
        "# GETTING PLOTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SV9TcHxDotZ"
      },
      "source": [
        "## Plotting utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HdbfF8jDm8R"
      },
      "source": [
        "def get_style():\n",
        "    '''give different line styles for plots'''\n",
        "    l = [\"-\",\"-.\",\":\",\"--\"]\n",
        "    for i in range(10000):\n",
        "        yield l[i % 4]\n",
        "\n",
        "def get_color():\n",
        "    '''give different line styles for plots'''\n",
        "    l = [\"red\",\"green\",\"blue\",\"grey\"]\n",
        "    for i in range(10000):\n",
        "        yield l[i % 4]\n",
        "\n",
        "STYLES = get_style() # generator for looping styles\n",
        "COLORS = get_color()\n",
        "\n",
        "def title_save(title=None, path=None, suff=\".png\"):\n",
        "    ''' add title and save plot '''\n",
        "    if title is not None:   \n",
        "        plt.title(title)\n",
        "    if path is not None:\n",
        "        plt.savefig(path + suff)\n",
        "\n",
        "def legendize(y):\n",
        "    ''' label axis of plt plot '''\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(y)\n",
        "    plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-b245eNov4b1"
      },
      "source": [
        "## Plotting from history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_uPE0aIC0Ai"
      },
      "source": [
        "# functions to display training history \n",
        "\n",
        "def means_bounds(arr):\n",
        "    ''' from array return 1 array of means, \n",
        "        1 for (mean - var), 1 for (mean + var)\n",
        "    '''\n",
        "    means = np.mean(arr, axis=0)\n",
        "    var = np.var(arr, axis = 0) \n",
        "    low, up = means - var, means + var\n",
        "    return means, low, up\n",
        "\n",
        "def plot_var(l_hist, l_idx):\n",
        "    '''add curve of asked indexes of history'''\n",
        "    arr_hist = np.asarray(l_hist)\n",
        "    # print(arr_hist.shape)\n",
        "    epochs = range(1, arr_hist.shape[2] + 1)\n",
        "    for idx in l_idx:\n",
        "        vals = arr_hist[:,idx,:]\n",
        "        vals_m, vals_l, vals_u = means_bounds(vals)\n",
        "        style, color = next(STYLES), next(COLORS)\n",
        "        plt.plot(epochs, vals_m, label=METRICS[idx], linestyle=style, color=color)\n",
        "        plt.fill_between(epochs, vals_u, vals_l, alpha=INTENS, color=color)\n",
        "\n",
        "def loss_var(l_hist, title=None, path=None):\n",
        "    ''' plot losses with variance from a list of historys '''\n",
        "    plot_var(l_hist, [0,1,2])\n",
        "    legendize(\"Training loss\")\n",
        "    title_save(title, path, suff=\"_loss.png\")\n",
        "    plt.show()\n",
        "\n",
        "def acc_var(l_hist, title=None, path=None):\n",
        "    ''' plot accuracy with variance from a list of historys '''\n",
        "    plot_var(l_hist, [3])\n",
        "    plt.ylim([0,1])\n",
        "    plt.grid(True, linewidth=1, axis='y', alpha=0.7)\n",
        "    legendize(\"Test Accuracy\")\n",
        "    title_save(title, path, suff=\"_acc.png\")\n",
        "    plt.show()\n",
        "\n",
        "def l2_var(l_hist, title=None, path=None):\n",
        "    '''plot l2 norm of gen model from a list of historys'''\n",
        "    plot_var(l_hist, [4,5])\n",
        "    legendize(\"l2 norm\")\n",
        "    title_save(title, path, suff=\"_l2.png\")\n",
        "    plt.show()\n",
        "\n",
        "def gradsp_var(l_hist, title=None, path=None):\n",
        "    ''' plot scalar product of gradients between 2 consecutive epochs\n",
        "        from a list of historys\n",
        "    '''\n",
        "    plot_var(l_hist, [6,7])\n",
        "    legendize(\"grad_sp\")\n",
        "    title_save(title, path, suff=\"_gradsp.png\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_metrics(l_hist, title=None, path=None):\n",
        "    '''plot and save the different metrics from list of historys'''\n",
        "    l2_var(l_hist, title, path)\n",
        "    loss_var(l_hist, title, path)\n",
        "    acc_var(l_hist, title, path)\n",
        "    gradsp_var(l_hist, title, path)\n",
        "\n",
        "# ------- from Flower ------------------\n",
        "\n",
        "def show_acc(flow, title=None, path=None):\n",
        "    ''' plot curves of accuracy evolution of a Flower '''\n",
        "    acc = flow.history[3]\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    plt.plot(epochs, acc, label='acc')\n",
        "    plt.ylim([0,1])\n",
        "    legendize(\"Test Accuracy\")\n",
        "    title_save(title, path, suff=\"_acc.png\")\n",
        "    plt.show()\n",
        "\n",
        "def show_loss(flow, title=None, path=None):\n",
        "    ''' plot curves of loss evolution of a Flower '''\n",
        "    fit, gen, reg, _ = flow.history\n",
        "    tot = [a + b + c for a, b, c in zip(fit, gen, reg)]\n",
        "    epochs = range(1, len(fit) + 1)\n",
        "    plt.plot(epochs, tot, label='tot', linestyle='-', color='red')\n",
        "    plt.plot(epochs, fit, label='fit', linestyle='-.')\n",
        "    plt.plot(epochs, gen, label='gen', linestyle=':')\n",
        "    plt.plot(epochs, reg, label='reg', linestyle='--')      #outputs results as a plot\n",
        "    legendize(\"Training loss\")\n",
        "    title_save(title, path, suff=\"_loss.png\")\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-_X32rvD9up"
      },
      "source": [
        "## Running and plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkv4sxEP3X0j"
      },
      "source": [
        "# functions to train and display history at the end\n",
        "\n",
        "def seedall(s):\n",
        "    '''seed all sources of randomness'''\n",
        "    reproducible = (s >= 0)\n",
        "    torch.manual_seed(s)\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "    torch.backends.cudnn.deterministic = reproducible\n",
        "    torch.backends.cudnn.benchmark     = not reproducible\n",
        "    print(\"\\nSeeded all to\", s)\n",
        "\n",
        "def add_acc_var(arr, label='acc'):\n",
        "    ''' from array add curve of accuracy '''\n",
        "    acc = arr[:,3,:]\n",
        "    means, low, up = means_bounds(acc)\n",
        "    epochs = range(1, len(means) + 1)\n",
        "    plt.plot(epochs, means, label=label, linestyle=next(STYLES))\n",
        "    plt.fill_between(epochs, up, low, alpha=0.4)\n",
        "\n",
        "def plot_runs_acc(l_runs, l_param, path=None):\n",
        "    ''' plot several acc_var on one graph, -l_param is for legend'''\n",
        "    arr = np.asarray(l_runs)\n",
        "    for run, param in zip(arr, l_param): # adding one curve for each parameter (run)\n",
        "        add_acc_var(run, str(param))\n",
        "    plt.ylim([0,1])\n",
        "    plt.grid(True, linewidth=1, axis='y', alpha=0.7)\n",
        "    legendize(\"Test Accuracy\")\n",
        "    title_save(title=path, path=path, suff=\".png\")\n",
        "    plt.show()\n",
        "\n",
        "# ---------- number of honest nodes -------------------------\n",
        "\n",
        "def get_flower_disp(nbn, verb=0, gpu=True):\n",
        "    '''initialize a flower and add -nbn honest nodes'''\n",
        "    w0 = 0.05 * nbn\n",
        "    ppn = 60_000 // nbn # points per node\n",
        "    flow = get_flower(w0, gpu)\n",
        "    flow.add_nodes(train, (nbn, ppn), \"honest\", w=0.005, verb=verb)\n",
        "    return flow\n",
        "\n",
        "def run_disp(nbn, verb=0, gpu=True):\n",
        "    ''' create a flower of honest nodes and trains it for 200 eps\n",
        "        display graphs of loss and accuracy \n",
        "        nbn : number of nodes\n",
        "    '''\n",
        "    l_hist = []\n",
        "    for s in SEEDS: # different seeds (global variable)\n",
        "        seedall(s)\n",
        "        flow = get_flower_disp(nbn, verb=verb, gpu=True)   \n",
        "        epochs = EPOCHS\n",
        "        flow.lr_node = 0.001\n",
        "        flow.lr_gen = 0.01\n",
        "        flow.gen_freq = 1\n",
        "        h = flow.train(epochs, verb=verb)\n",
        "        flow.check()\n",
        "        l_hist.append(h)\n",
        "        print(\"\\n\")\n",
        "    text = \"nbn : {}, lrnode : {}, lrgen : {}, genfrq : {}, eps :{}\"\n",
        "    title = text.format(nbn, flow.lr_node, \n",
        "                        flow.lr_gen, flow.gen_freq, epochs)\n",
        "    path = \"disp/disp_{}\".format(nbn)\n",
        "    plot_metrics(l_hist, title, path)   \n",
        "    return l_hist # all historys\n",
        "\n",
        "def run_disp_mult(l_nbn, verb=0, gpu=True):\n",
        "    ''' iterate run_disp with a list of different parameters '''\n",
        "    l_runs = [] # list of historys for each parameter\n",
        "    os.makedirs(\"disp\", exist_ok=True)\n",
        "    for nbn in l_nbn:\n",
        "        l_hist = run_disp(nbn, verb, gpu)\n",
        "        l_runs.append(l_hist)\n",
        "    plot_runs_acc(l_runs, l_nbn, \"disp/disp_mult\")\n",
        "    return l_runs\n",
        "\n",
        "\n",
        "# ----------- proportion of dishonest nodes  ------------\n",
        "\n",
        "def get_flower_fracdish(frac, typ, verb=0,  gpu=True):\n",
        "    ''' initialize and add nodes according to parameters '''\n",
        "    nbn = 1000\n",
        "    w0 = 0.05 * nbn\n",
        "    flow = get_flower(w0, gpu)\n",
        "    ppn = 60_000 // nbn # points per node\n",
        "    nbbyz = int(frac * nbn)\n",
        "    nbh = nbn - nbbyz\n",
        "    flow.add_nodes(train, (nbh, ppn), \"honest\", w=0.005)\n",
        "    flow.add_nodes(train, (nbbyz, ppn), typ, w=0.005)\n",
        "    return flow\n",
        "\n",
        "def run_fracdish(frac, typ, verb=0, gpu=True):\n",
        "    ''' create a flower of honest nodes and trains it for 200 eps\n",
        "        display graphs of loss and accuracy \n",
        "        frac : fraction of dishonest nodes\n",
        "    '''\n",
        "    l_hist = []\n",
        "    for s in SEEDS:\n",
        "        seedall(s)\n",
        "        flow = get_flower_fracdish(frac, typ, verb, gpu)\n",
        "        epochs = EPOCHS\n",
        "        flow.lr_node = 0.001\n",
        "        flow.lr_gen = 0.01\n",
        "        flow.gen_freq = 1\n",
        "        h = flow.train(epochs, verb=verb)\n",
        "        flow.check()\n",
        "        l_hist.append(h)\n",
        "    text = \"frac : {}, nbn : {}, lrnode : {}, lrgen : {}, genfrq : {}, eps :{}\"\n",
        "    title = text.format(frac, flow.nb_nodes, flow.lr_node, \n",
        "                        flow.lr_gen, flow.gen_freq, epochs)\n",
        "    path = \"fracdish/fracdish_{}\".format(int(100*frac)) # percentage\n",
        "    plot_metrics(l_hist, title, path)    \n",
        "    return l_hist\n",
        "\n",
        "def run_fracdish_mult(l_frac, typ=\"zeros\", verb=0, gpu=True):\n",
        "    '''iterate run_fracdish with a list of fracs'''\n",
        "    l_runs = [] # list of historys for each parameter\n",
        "    os.makedirs(\"fracdish\", exist_ok=True)\n",
        "    for frac in l_frac:\n",
        "        l_hist = run_fracdish(frac, typ, verb, gpu)\n",
        "        l_runs.append(l_hist)\n",
        "    plot_runs_acc(l_runs, l_frac, \"fracdish/fracdish_mult\")\n",
        "    return l_runs\n",
        "\n",
        "# ------------- heterogeneity of data --------------------\n",
        "\n",
        "def get_flower_heter(heter, frac=0, typ=\"zeros\", verb=0, gpu=True):\n",
        "    ''' initialize and add nodes according to parameters ''' \n",
        "    nbn = 1000\n",
        "    w0 = 0.05 * nbn\n",
        "    flow = get_flower(w0, gpu)\n",
        "    ppn = 60_000 // nbn # points per node\n",
        "    nbbyz = int(frac * nbn)\n",
        "    nbh = nbn - nbbyz\n",
        "    nbh_lab = nbh // 10 # for each label\n",
        "    nbbyz_lab = nbbyz // 10\n",
        "    nb_lab = nbh_lab + nbbyz_lab\n",
        "    for lab in range(10): # for each label\n",
        "        flow.add_nodes(train, (nbh_lab, ppn), \"honest\", (lab, heter), verb=verb, w=0.005)\n",
        "        flow.add_nodes(train, (nbbyz_lab, ppn), typ, (lab, heter), verb=verb, w=0.005)\n",
        "        if gpu:\n",
        "            flow.set_localtest(test_gpu, 100, range(lab * nb_lab, (lab + 1) * nb_lab), (lab, heter))\n",
        "        else:\n",
        "            flow.set_localtest(test, 100, range(lab * nb_lab, (lab + 1) * nb_lab), (lab, heter))\n",
        "    return flow\n",
        "\n",
        "def run_heter(heter, frac=0, typ=\"zeros\", verb=0, gpu=True):\n",
        "    ''' create a flower of honest nodes and trains it for 200 eps\n",
        "        display graphs of loss and accuracy \n",
        "        frac : fraction of dishonest nodes\n",
        "        heter : heterogeneity of data\n",
        "    '''\n",
        "    l_hist = []\n",
        "    for s in SEEDS:\n",
        "        seedall(s)\n",
        "        flow = get_flower_heter(heter, frac, typ, verb, gpu)\n",
        "        epochs = EPOCHS\n",
        "        flow.lr_node = 0.001\n",
        "        flow.lr_gen = 0.01\n",
        "        flow.gen_freq = 1\n",
        "        h = flow.train(epochs, verb=verb)\n",
        "        flow.check()\n",
        "        l_hist.append(h)\n",
        "    t1 = \"heter : {}, nbn : {}, lrnode : {}, lrgen : {}, genfrq : {}, eps :{}\" \n",
        "    t2 = \"\\nfrac : {}, type : \" + typ \n",
        "    text = t1 + t2\n",
        "    title = text.format(heter, flow.nb_nodes, flow.lr_node, \n",
        "                        flow.lr_gen, flow.gen_freq, epochs, frac)\n",
        "    path = \"heter/heter_{}\".format(heter)\n",
        "    plot_metrics(l_hist, title, path)     \n",
        "    return l_hist\n",
        "\n",
        "def run_heter_mult(l_heter, frac=0, typ=\"zeros\", verb=0, gpu=True):\n",
        "    '''iterate run_heter with a list of fracs'''\n",
        "    l_runs = [] # list of historys for each parameter\n",
        "    os.makedirs(\"heter\", exist_ok=True)\n",
        "    for heter in l_heter:\n",
        "        l_hist = run_heter(heter, frac, typ, verb, gpu)\n",
        "        l_runs.append(l_hist)\n",
        "    plot_runs_acc(l_runs, l_heter, \"heter/heter_mult\")\n",
        "    return l_runs\n",
        "\n",
        "# - heterogeneity of data with different styles of notation depending on nodes -\n",
        "\n",
        "def get_flower_heter_strats(heter, verb=0, gpu=True):\n",
        "    '''initialize and add nodes according to parameter'''\n",
        "    global FORCING1\n",
        "    global FORCING2\n",
        "    global FORCE    \n",
        "    nbn = 1000\n",
        "    w0 = 0.05 * nbn\n",
        "    flow = get_flower(w0, gpu)\n",
        "    ppn = 60_000 // nbn # points per node\n",
        "    nb_lab = nbn // 10\n",
        "    FORCE = True\n",
        "    for lab in range(10):\n",
        "        for n in range(nb_lab):\n",
        "            FORCING1, FORCING2 = -1, -1\n",
        "            flow.add_nodes(train, (1, ppn), \"strats\", (lab, heter), w=0.005, verb=verb)\n",
        "            flow.set_localtest(test_gpu, 100, [lab * nb_lab + n], (lab, heter), typ=\"strats\")\n",
        "    FORCE = False\n",
        "    return flow\n",
        "\n",
        "def run_heter_strats(heter, verb=0, gpu=True):\n",
        "    ''' create a flower of honest nodes and trains it for 200 eps\n",
        "        display graphs of loss and accuracy \n",
        "        heter : heterogeneity of data\n",
        "    '''\n",
        "    flow = get_flower_heter_strats(heter, verb, gpu)\n",
        "    epochs = EPOCHS\n",
        "    flow.lr_node = 0.001\n",
        "    flow.lr_gen = 0.01\n",
        "    flow.gen_freq = 1\n",
        "    h = flow.train(epochs, verb=verb)\n",
        "    flow.check()\n",
        "    t1 = \"heter : {}, nbn : {}, lrnode : {}, lrgen : {}, genfrq : {}, eps :{}\" \n",
        "    t2 = \"\\ntype : only strats\" \n",
        "    text = t1 + t2\n",
        "    title = text.format(heter, flow.nb_nodes, flow.lr_node, \n",
        "                        flow.lr_gen, flow.gen_freq, epochs)\n",
        "    plot_metrics([h], title, path)    \n",
        "    return flow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHox-Z1iF7nP"
      },
      "source": [
        "EPOCHS = 30\n",
        "SEEDS = [3]\n",
        "l_param = [0,5]\n",
        "l_hist = run_heter_mult(l_param, verb=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwCV-Heyvw9u"
      },
      "source": [
        "## Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCGkrKXjDOob"
      },
      "source": [
        " def compare(flow_centr, flow_distr): # for run_heter\n",
        "    ''' return average accuracy on local test sets \n",
        "        for both centralized and distributed models\n",
        "    '''\n",
        "    central, gen, distr = 0, 0, 0\n",
        "    N = flow_distr.nb_nodes\n",
        "    for lab in range(10):\n",
        "        sc = score(flow_centr.models[0], flow_distr.localtest[1][lab])\n",
        "        central += sc\n",
        "    for lab in range(10):\n",
        "        sc = score(flow_distr.general_model, flow_distr.localtest[1][lab])\n",
        "        gen += sc\n",
        "    for n in range(N):\n",
        "        sc = flow_distr.test_loc(n)\n",
        "        distr += sc\n",
        "    distr = distr / N\n",
        "    central = central / 10\n",
        "    gen = gen / 10\n",
        "    return central, gen, distr\n",
        "\n",
        " def compare2(flow_centr, flow_distr): # for run_heter_strats\n",
        "    ''' return average accuracy on local test sets \n",
        "        for both centralized and distributed models\n",
        "    '''\n",
        "    central, gen, distr = 0, 0, 0\n",
        "    N = flow_distr.nb_nodes\n",
        "    for n in range(N):\n",
        "        sc = score(flow_centr.models[0], flow_distr.localtest[1][n])\n",
        "        central += sc\n",
        "    for n in range(N):\n",
        "        sc = score(flow_distr.general_model, flow_distr.localtest[1][n])\n",
        "        gen += sc\n",
        "    for n in range(N):\n",
        "        sc = flow_distr.test_loc(n)\n",
        "        distr += sc\n",
        "    distr = distr / N\n",
        "    central = central / N\n",
        "    gen = gen / N\n",
        "    return central, gen, distr "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VOWD2aPGT43"
      },
      "source": [
        "# MANUAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTX8hvSTTWIY"
      },
      "source": [
        "seedall(0)\n",
        "tulip = get_flower(0.05, gpu=True)\n",
        "tulip.add_nodes(train, (10, 6000), \"honest\", w=0.05)\n",
        "tulip.check()\n",
        "tulip.w = 0.5\n",
        "tulip.lr_node = 0.1\n",
        "tulip.lr_gen = 0.01\n",
        "tulip.gen_freq = 1\n",
        "h1 = tulip.train(10, test_freq=1, verb=2)\n",
        "tulip.check()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}